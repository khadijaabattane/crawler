# Web Indexing - TPs

## Web Crawler - TP1 ENSAI 2025 ğŸ•¸ï¸

Ce projet implÃ©mente un crawler web en Python. Le script explore des pages web, extrait des informations clÃ©s et priorise certaines pages selon des critÃ¨res dÃ©finis.


## âœ¨ FonctionnalitÃ©s

- **Extraction des donnÃ©es** :
  - Titre de la page.
  - Premier paragraphe.
  - Liste des liens internes.
- **Priorisation des URLs** :
  - Priorise les liens contenant le mot-clÃ© `product`.
- **Limitation du crawling** :
  - ArrÃªt aprÃ¨s avoir visitÃ© 50 pages.
- **Respect de robots.txt** :
  - VÃ©rifie les permissions avant de crawler une URL.
- **Stockage des rÃ©sultats** :
  - Les donnÃ©es sont sauvegardÃ©es dans un fichier JSON structurÃ©.


## ğŸ› ï¸ Installation

1. **Cloner le dÃ©pÃ´t** :
   ```bash
   git clone https://github.com/khadijaabattane/crawler.git
   cd crawler
   ```

2. **Installer les dÃ©pendances** :
   ```bash
   pip install -r requirements.txt
   ```

3. **ExÃ©cuter le script** :
   ```bash
   python crawler.py
   ```


## ğŸ“‚ Structure du projet

```plaintext
â”œâ”€â”€ crawler.py   
â”œâ”€â”€ results.json         
â”œâ”€â”€ requirements.txt     
â”œâ”€â”€ README.md            
```


## ğŸ–¥ï¸ PrÃ©-requis

- BibliothÃ¨ques : `requests`, `beautifulsoup4`


# Web Indexing - TP2


## ğŸ“Œ Project Description
This project aims to implement an **inverted indexing system** for a set of web products, allowing fast searches on product titles, descriptions, reviews, and features.

The Python script provides the following functionalities:
- **Extract product information** from a `products.jsonl` file
- **Create an inverted index** for titles and descriptions
- **Generate positional indexes** for words in titles and descriptions
- **Build a review index** (total reviews, average rating, last rating)
- **Index product features** (brand, origin, etc.)
- **Save and load indexes** in JSON format

## ğŸ“‚ Generated Files Structure
The script generates the following files in the `indexes/` directory:

| **File Name**                        | **Content** |
|--------------------------------------|------------|
| `title_index.json` | Inverted index for titles (word -> list of URLs) |
| `description_index.json` | Inverted index for descriptions (word -> list of URLs) |
| `title_positional_index.json` | Positional index for words in titles |
| `description_positional_index.json` | Positional index for words in descriptions |
| `reviews_index.json` | Review index (total reviews, average score, last score) |
| `features_index.json` | Inverted index for features (brand, origin, etc.) |

## ğŸ› ï¸ Index Implementation

### 1ï¸âƒ£ Inverted Index for Titles and Descriptions
- **Format:** `{ "word": ["URL1", "URL2", ...] }`
- **Purpose:** Enables quick lookup of documents containing a specific word.

### 2ï¸âƒ£ Positional Index for Titles and Descriptions
- **Format:** `{ "word": { "URL": [positions] } }`
- **Purpose:** Stores word positions to facilitate proximity-based searching.

### 3ï¸âƒ£ Review Index
- **Format:** `{ "URL": { "total_reviews": X, "average_score": Y, "last_score": Z } }`
- **Purpose:** Helps prioritize the highest-rated products.

### 4ï¸âƒ£ Feature Index (Brand, Origin, etc.)
- **Format:** `{ "feature": { "value": ["URL1", "URL2"] } }`
- **Purpose:** Enables filtering products based on characteristics.

## ğŸš€ Running the Script
### 1ï¸âƒ£ Install Dependencies
No external dependencies are required; Python 3 is sufficient.

### 2ï¸âƒ£ Execute the Script
```bash
python indexer.py
```

### 3ï¸âƒ£ Verify the Indexes
The generated JSON files are located in the `indexes/` directory.





---

### **ğŸš€ TP3: Search Engine Using Indexing and Ranking**

# ğŸ“Œ **Search Engine for Indexed Product Data**
This project is a **fast and efficient search engine** designed to query indexed product data. It supports:
- **Spelling correction** ğŸ“
- **Query expansion using synonyms** ğŸ”„
- **BM25 ranking for relevance** ğŸ“Š
- **Parallelized search for speed** âš¡
- **Query history logging** ğŸ—‚ï¸
- **Auto-suggestions for queries** ğŸ’¡

---

## **ğŸ“– 1ï¸âƒ£ Use Cases & Features Implemented**
This search engine addresses multiple challenges commonly found in **text-based information retrieval systems**.

| **Feature** | **Problem Solved** | **Solution Implemented** |
|------------|------------------|----------------------|
| **Indexing** | Fast document lookup | Created **inverted indexes** for title, description, brand, origin, reviews, and domain |
| **Tokenization** | Normalize user input | Applied **NLTK stopwords filtering + punctuation removal** |
| **Spelling Correction** | Handle typos | Used **TextBlob correction** & **Fuzzy Matching** with `rapidfuzz` |
| **Query Expansion** | Improve recall with synonyms | Used **synonym mapping** (origin-based synonyms from `origin_synonyms.json`) |
| **Ranking (BM25)** | Prioritize most relevant results | Implemented **precomputed TF-IDF and BM25 scoring** |
| **Parallel Processing** | Speed up searches | Used **multithreading** (`threading.Thread`) for search execution |
| **Query Logging** | Maintain search history | Saved **all queries & results** in `query_history.json` |
| **Auto-suggestions** | Help users with queries | Built a **Trie-based suggestion system** for fast lookup |

---

## **ğŸ› ï¸ 2ï¸âƒ£ Installation & Setup**
### **ğŸ”¹ Install Dependencies**
This project uses Python 3 and requires some external libraries. Install them using:
```sh
pip install nltk textblob rapidfuzz
```

> ğŸ› ï¸ **Note**: You may need to download the **NLTK stopwords**:
```python
import nltk
nltk.download('stopwords')
```

---

## **ğŸ’¡ 3ï¸âƒ£ How It Works**
### **ğŸ” Search Process**
1. **User enters a search query** (e.g., `"choco"`)
2. **Spelling correction is applied** (e.g., `"chocolate"`)
3. **Query expansion happens** (if applicable)
4. **Tokenization removes stopwords** (e.g., `"the best chocolate"` â†’ `["chocolate"]`)
5. **Parallelized search runs**:
   - Looks up words in **title, description, brand, origin, and reviews**
   - Applies **BM25 ranking** to score results
6. **Results are sorted** by **relevance score**
7. **Results are displayed in the terminal** & **logged in `query_history.json`**

---

## **ğŸ–¥ï¸ 4ï¸âƒ£ Usage**
### **Run the Search Engine**
To start the search engine:
```sh
python search_engine.py
```
You will be prompted to enter a query:
```
ğŸ” Enter your search query: chocolate
```

### **Example Terminal Output**
```
ğŸ” **Suggestions:** ['chocolate']

ğŸ” **Final Tokenized Query:** ['chocolate']

ğŸ” **Search Results:**

ğŸ“Œ **Product:** Box Of Chocolate Candy
ğŸ”— URL: https://web-scraping.dev/product/1
â­ Score: 15.2
ğŸ¯ Matches: Title match: chocolate, Review score: 4.5 (Total reviews: 12)

ğŸ“Œ **Product:** Dark Chocolate Bar
ğŸ”— URL: https://web-scraping.dev/product/3
â­ Score: 12.8
ğŸ¯ Matches: Title match: chocolate, Review score: 4.2 (Total reviews: 8)

âœ… Query and results saved to `query_history.json`
```

---

## **ğŸ“‚ 5ï¸âƒ£ Query History Logging**
Each search is saved in `query_history.json`:
```json
[
    {
        "query": "chocolate candy",
        "metadata": {
            "total_documents": 156,
            "filtered_documents": 2
        },
        "results": [
            {
                "title": "Box of Chocolate Candy",
                "url": "https://web-scraping.dev/product/1",
                "description": "Indulge your sweet tooth...",
                "score": 15.2,
                "matches": ["Title match: chocolate", "Review score: 4.5"]
            }
        ]
    }
]
```

-


 

---

## **ğŸ“œ 8ï¸âƒ£ Full Project Structure**
```
ğŸ“‚ search-engine
â”‚â”€â”€ ğŸ”¹ search_engine.py    
â”‚â”€â”€ ğŸ”¹ title_index.json    
â”‚â”€â”€ ğŸ”¹ description_index.json  
â”‚â”€â”€ ğŸ”¹ reviews_index.json  
â”‚â”€â”€ ğŸ”¹ origin_index.json   
â”‚â”€â”€ ğŸ”¹ brand_index.json    
â”‚â”€â”€ ğŸ”¹ domain_index.json   
â”‚â”€â”€ ğŸ”¹ origin_synonyms.json 
â”‚â”€â”€ ğŸ”¹ query_history.json  
â”‚â”€â”€ ğŸ”¹ README.md           
```

---
## ğŸ“ Authors
- **Khadija ABATTANE** - ENSAI 3A


